[2023-03-22T01:20:47.797+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T01:20:47.835+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T01:20:47.837+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T01:20:47.840+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-22T01:20:47.843+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T01:20:47.911+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-21 00:00:00+00:00
[2023-03-22T01:20:48.052+0000] {taskinstance.py:1078} INFO - Dependencies not met for <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [running]>, dependency 'Task Instance Not Running' FAILED: Task is in the running state
[2023-03-22T01:20:48.061+0000] {taskinstance.py:1078} INFO - Dependencies not met for <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [running]>, dependency 'Task Instance State' FAILED: Task is in the 'running' state.
[2023-03-22T01:20:48.082+0000] {local_task_job.py:151} INFO - Task is not able to be run
[2023-03-22T01:20:48.106+0000] {standard_task_runner.py:55} INFO - Started process 60 to run task
[2023-03-22T01:20:48.154+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-21T00:00:00+00:00', '--job-id', '170', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmpl4ugql7p']
[2023-03-22T01:20:48.161+0000] {standard_task_runner.py:83} INFO - Job 170: Subtask extract_csv_file
[2023-03-22T01:20:48.421+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-22T01:20:48.808+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-21T00:00:00+00:00
[2023-03-22T01:20:49.095+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-22T01:20:49.156+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230321T000000, start_date=20230322T012047, end_date=20230322T012049
[2023-03-22T01:20:49.288+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-22T01:20:49.420+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-22T02:28:32.417+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:28:32.441+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:28:32.443+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:28:32.445+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-22T02:28:32.447+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:28:32.480+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-21 00:00:00+00:00
[2023-03-22T02:28:32.493+0000] {standard_task_runner.py:55} INFO - Started process 175 to run task
[2023-03-22T02:28:32.503+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-21T00:00:00+00:00', '--job-id', '182', '--raw', '--subdir', 'DAGS_FOLDER/load_csv.py', '--cfg-path', '/tmp/tmpz6s4aauk']
[2023-03-22T02:28:32.506+0000] {standard_task_runner.py:83} INFO - Job 182: Subtask extract_csv_file
[2023-03-22T02:28:32.633+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-22T02:28:32.772+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Sanvi
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-21T00:00:00+00:00
[2023-03-22T02:28:33.266+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-22T02:28:33.286+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230321T000000, start_date=20230322T022832, end_date=20230322T022833
[2023-03-22T02:28:33.412+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-22T02:28:33.498+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-22T02:30:27.710+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:30:27.728+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:30:27.730+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:30:27.732+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-22T02:30:27.734+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:30:27.760+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-21 00:00:00+00:00
[2023-03-22T02:30:27.770+0000] {standard_task_runner.py:55} INFO - Started process 214 to run task
[2023-03-22T02:30:27.779+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-21T00:00:00+00:00', '--job-id', '185', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmp4ny1mvjl']
[2023-03-22T02:30:27.781+0000] {standard_task_runner.py:83} INFO - Job 185: Subtask extract_csv_file
[2023-03-22T02:30:27.909+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-22T02:30:28.151+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-21T00:00:00+00:00
[2023-03-22T02:30:28.334+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-22T02:30:28.359+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230321T000000, start_date=20230322T023027, end_date=20230322T023028
[2023-03-22T02:30:28.449+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-22T02:30:28.580+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-22T02:36:12.603+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:36:12.623+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:36:12.625+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:36:12.627+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-22T02:36:12.629+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:36:12.655+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-21 00:00:00+00:00
[2023-03-22T02:36:12.665+0000] {standard_task_runner.py:55} INFO - Started process 312 to run task
[2023-03-22T02:36:12.675+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-21T00:00:00+00:00', '--job-id', '188', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmp45kigpvd']
[2023-03-22T02:36:12.678+0000] {standard_task_runner.py:83} INFO - Job 188: Subtask extract_csv_file
[2023-03-22T02:36:12.799+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-22T02:36:13.123+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-21T00:00:00+00:00
[2023-03-22T02:36:13.192+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-22T02:36:13.218+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230321T000000, start_date=20230322T023612, end_date=20230322T023613
[2023-03-22T02:36:13.298+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-22T02:36:13.396+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-22T02:43:45.358+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:43:45.383+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [queued]>
[2023-03-22T02:43:45.385+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:43:45.387+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-22T02:43:45.389+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-22T02:43:45.440+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-21 00:00:00+00:00
[2023-03-22T02:43:45.454+0000] {standard_task_runner.py:55} INFO - Started process 448 to run task
[2023-03-22T02:43:45.472+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-21T00:00:00+00:00', '--job-id', '191', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmp8fvxfbgi']
[2023-03-22T02:43:45.475+0000] {standard_task_runner.py:83} INFO - Job 191: Subtask extract_csv_file
[2023-03-22T02:43:45.616+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-21T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-22T02:43:45.916+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-21T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-21T00:00:00+00:00
[2023-03-22T02:43:46.036+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-22T02:43:46.059+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230321T000000, start_date=20230322T024345, end_date=20230322T024346
[2023-03-22T02:43:46.106+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-22T02:43:46.164+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
