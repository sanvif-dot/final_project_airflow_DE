[2023-03-21T13:11:43.427+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T13:11:43.504+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T13:11:43.508+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T13:11:43.511+0000] {taskinstance.py:1283} INFO - Starting attempt 3 of 3
[2023-03-21T13:11:43.515+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T13:11:43.683+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-20 00:00:00+00:00
[2023-03-21T13:11:43.710+0000] {standard_task_runner.py:55} INFO - Started process 872 to run task
[2023-03-21T13:11:43.746+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-20T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/load_csv.py', '--cfg-path', '/tmp/tmp2_jbak4g']
[2023-03-21T13:11:43.754+0000] {standard_task_runner.py:83} INFO - Job 21: Subtask extract_csv_file
[2023-03-21T13:11:44.199+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-21T13:11:44.657+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-20T00:00:00+00:00
[2023-03-21T13:11:44.857+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-21T13:11:44.926+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230320T000000, start_date=20230321T131143, end_date=20230321T131144
[2023-03-21T13:11:45.066+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-21T13:11:45.294+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-21T13:44:50.833+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T13:44:50.863+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T13:44:50.865+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T13:44:50.867+0000] {taskinstance.py:1283} INFO - Starting attempt 3 of 3
[2023-03-21T13:44:50.869+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T13:44:50.923+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-20 00:00:00+00:00
[2023-03-21T13:44:50.942+0000] {standard_task_runner.py:55} INFO - Started process 1598 to run task
[2023-03-21T13:44:50.964+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-20T00:00:00+00:00', '--job-id', '89', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmp3320vbmz']
[2023-03-21T13:44:50.973+0000] {standard_task_runner.py:83} INFO - Job 89: Subtask extract_csv_file
[2023-03-21T13:44:51.191+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-21T13:44:51.496+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-20T00:00:00+00:00
[2023-03-21T13:44:51.587+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-21T13:44:51.611+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230320T000000, start_date=20230321T134450, end_date=20230321T134451
[2023-03-21T13:44:51.721+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-21T13:44:51.794+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-21T14:52:35.839+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T14:52:35.894+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T14:52:35.903+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T14:52:35.905+0000] {taskinstance.py:1283} INFO - Starting attempt 3 of 3
[2023-03-21T14:52:35.907+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T14:52:35.987+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-20 00:00:00+00:00
[2023-03-21T14:52:36.011+0000] {standard_task_runner.py:55} INFO - Started process 2738 to run task
[2023-03-21T14:52:36.033+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-20T00:00:00+00:00', '--job-id', '101', '--raw', '--subdir', 'DAGS_FOLDER/load_csv.py', '--cfg-path', '/tmp/tmpa8b0vxgw']
[2023-03-21T14:52:36.049+0000] {standard_task_runner.py:83} INFO - Job 101: Subtask extract_csv_file
[2023-03-21T14:52:36.442+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-21T14:52:36.815+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-20T00:00:00+00:00
[2023-03-21T14:52:36.948+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-21T14:52:36.991+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230320T000000, start_date=20230321T145235, end_date=20230321T145236
[2023-03-21T14:52:37.147+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-21T14:52:37.337+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-21T15:17:08.174+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T15:17:08.212+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T15:17:08.215+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T15:17:08.216+0000] {taskinstance.py:1283} INFO - Starting attempt 3 of 3
[2023-03-21T15:17:08.218+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T15:17:08.271+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-20 00:00:00+00:00
[2023-03-21T15:17:08.306+0000] {standard_task_runner.py:55} INFO - Started process 3160 to run task
[2023-03-21T15:17:08.336+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-20T00:00:00+00:00', '--job-id', '116', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmpyz1wv333']
[2023-03-21T15:17:08.347+0000] {standard_task_runner.py:83} INFO - Job 116: Subtask extract_csv_file
[2023-03-21T15:17:08.587+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-21T15:17:08.813+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-20T00:00:00+00:00
[2023-03-21T15:17:08.887+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-21T15:17:08.925+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230320T000000, start_date=20230321T151708, end_date=20230321T151708
[2023-03-21T15:17:09.042+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-21T15:17:09.145+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-21T15:31:24.262+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T15:31:24.351+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T15:31:24.357+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T15:31:24.364+0000] {taskinstance.py:1283} INFO - Starting attempt 3 of 3
[2023-03-21T15:31:24.368+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T15:31:24.679+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-20 00:00:00+00:00
[2023-03-21T15:31:24.789+0000] {standard_task_runner.py:55} INFO - Started process 3427 to run task
[2023-03-21T15:31:24.929+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-20T00:00:00+00:00', '--job-id', '128', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmpv3s737ei']
[2023-03-21T15:31:24.952+0000] {standard_task_runner.py:83} INFO - Job 128: Subtask extract_csv_file
[2023-03-21T15:31:25.555+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-21T15:31:26.566+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-20T00:00:00+00:00
[2023-03-21T15:31:26.771+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-21T15:31:26.865+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230320T000000, start_date=20230321T153124, end_date=20230321T153126
[2023-03-21T15:31:26.992+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-21T15:31:27.463+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-03-21T15:52:24.614+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T15:52:24.635+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [queued]>
[2023-03-21T15:52:24.637+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T15:52:24.639+0000] {taskinstance.py:1283} INFO - Starting attempt 3 of 3
[2023-03-21T15:52:24.642+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-21T15:52:24.691+0000] {taskinstance.py:1303} INFO - Executing <Task(PythonOperator): extract_csv_file> on 2023-03-20 00:00:00+00:00
[2023-03-21T15:52:24.725+0000] {standard_task_runner.py:55} INFO - Started process 3818 to run task
[2023-03-21T15:52:24.745+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'batch_pipeline', 'extract_csv_file', 'scheduled__2023-03-20T00:00:00+00:00', '--job-id', '152', '--raw', '--subdir', 'DAGS_FOLDER/batch_pipeline.py', '--cfg-path', '/tmp/tmp2uyrtk2b']
[2023-03-21T15:52:24.759+0000] {standard_task_runner.py:83} INFO - Job 152: Subtask extract_csv_file
[2023-03-21T15:52:24.975+0000] {task_command.py:388} INFO - Running <TaskInstance: batch_pipeline.extract_csv_file scheduled__2023-03-20T00:00:00+00:00 [running]> on host 070f7bf9e1a1
[2023-03-21T15:52:25.291+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Pedrosa
AIRFLOW_CTX_DAG_ID=batch_pipeline
AIRFLOW_CTX_TASK_ID=extract_csv_file
AIRFLOW_CTX_EXECUTION_DATE=2023-03-20T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-20T00:00:00+00:00
[2023-03-21T15:52:25.442+0000] {python.py:177} INFO - Done. Returned value was: None
[2023-03-21T15:52:25.526+0000] {taskinstance.py:1326} INFO - Marking task as SUCCESS. dag_id=batch_pipeline, task_id=extract_csv_file, execution_date=20230320T000000, start_date=20230321T155224, end_date=20230321T155225
[2023-03-21T15:52:25.654+0000] {local_task_job.py:212} INFO - Task exited with return code 0
[2023-03-21T15:52:25.886+0000] {taskinstance.py:2585} INFO - 1 downstream tasks scheduled from follow-on schedule check
